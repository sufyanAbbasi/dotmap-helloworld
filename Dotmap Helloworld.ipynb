{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import array, math, os, psycopg2, random\n",
    "from shapely.geometry import *\n",
    "from shapely.wkb import loads\n",
    "from multiprocessing import Pool\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "\n",
    "def init_capture(capture_dir):\n",
    "    # Create capture dir if it doesn't exist\n",
    "    if not os.path.exists(capture_dir):\n",
    "        os.makedirs(capture_dir)\n",
    "\n",
    "def format_tabblock_url(state):\n",
    "    # URL for FIPS and GNIS codes file -- https://www.census.gov/geo/reference/docs/state.txt'\n",
    "    return 'ftp://ftp2.census.gov/geo/tiger/TIGER2010/TABBLOCK/2010/tl_2010_{0}_tabblock10.zip'.format(state)\n",
    "\n",
    "def format_lodes7_od_url(st, part, t, year):\n",
    "    #http://lehd.ces.census.gov/data/lodes/LODES7/LODESTechDoc7.0.pdf\n",
    "    return 'http://lehd.ces.census.gov/data/lodes/LODES7/{0}/od/{0}_od_{1}_{2}_{3}.csv.gz'.format(st, part, t, year)\n",
    "\n",
    "def download_file(url, filename):\n",
    "    command = \"wget %s -O %s\" % (url, filename)\n",
    "    print \"Downloading %s to %s\" % (url, filename)\n",
    "    !$command\n",
    "\n",
    "def unzip_tabblock(filename, exdir):\n",
    "    command = \"unzip %s -d %s\" % (filename, exdir)\n",
    "    print \"Unzip %s to %s\" % (filename, exdir)\n",
    "    !$command\n",
    "\n",
    "def gunzip_lodes(filename):\n",
    "    command = \"gunzip %s\" % filename\n",
    "    print \"Unzip %s\" % filename\n",
    "    !$command\n",
    "\n",
    "def create_od_table(state):\n",
    "    s =(\n",
    "        \"DROP TABLE IF EXISTS %s_od_jt00_2011;\\n\"\n",
    "        \"CREATE TABLE %s_od_jt00_2011 ( \"\n",
    "        \"gid serial NOT NULL, \"\n",
    "        \"w_geocode character varying(15), \"\n",
    "        \"h_geocode character varying(15), \"\n",
    "        \"S000 integer, \"\n",
    "        \"SA01 integer, \" \n",
    "        \"SA02 integer, \"\n",
    "        \"SA03 integer, \"\n",
    "        \"SE01 integer, \"\n",
    "        \"SE02 integer, \"\n",
    "        \"SE03 integer, \"\n",
    "        \"SI01 integer, \"\n",
    "        \"SI02 integer, \"\n",
    "        \"SI03 integer, \"\n",
    "        \"createdate character varying(8));\\n\"\n",
    "    ) % (state,state)\n",
    "    return s\n",
    "\n",
    "def copy_cvs_to_psql(state,filename):\n",
    "    s = (\n",
    "         \"COPY %s_od_jt00_2011(\"\n",
    "         \"w_geocode,h_geocode,S000,SA01,\"\n",
    "         \"SA02,SA03,SE01,SE02,SE03,SI01,\"\n",
    "         \"SI02,SI03,createdate) FROM \"\n",
    "         \"'%s' \"\n",
    "        \"DELIMITER ',' CSV HEADER;\\n\"\n",
    "         ) % (state, filename)\n",
    "    return s\n",
    "\n",
    "def LonLatToPixelXY(lonlat, scale = 1.):\n",
    "    (lon, lat) = lonlat\n",
    "    x = (lon + 180.0) * 256.0 / 360.0\n",
    "    y = 128.0 - math.log(math.tan((lat + 90.0) * math.pi / 360.0)) * 128.0 / math.pi\n",
    "    return [x*scale, y*scale]\n",
    "\n",
    "def randomPoint(geom):\n",
    "    poly = loads(geom, True)\n",
    "    bbox = poly.bounds\n",
    "    l,b,r,t = bbox\n",
    "    while True:\n",
    "        point = Point(random.uniform(l,r),random.uniform(t,b))\n",
    "        if point is None:\n",
    "            break\n",
    "        if poly.contains(point):\n",
    "            break\n",
    "    return point.__geo_interface__['coordinates']\n",
    "\n",
    "def split_list(alist, wanted_parts=1):\n",
    "    length = len(alist)\n",
    "    return [ alist[i*length // wanted_parts: (i+1)*length // wanted_parts] \n",
    "             for i in range(wanted_parts) ]\n",
    "\n",
    "def my_range(start, end, step):\n",
    "    while start <= end:\n",
    "        yield start\n",
    "        start += step\n",
    "\n",
    "def get_count(conn, table):\n",
    "    query = \"SELECT count(*) FROM %s\" % table\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    return rows\n",
    "    \n",
    "def pack_color(color):\n",
    "    return color['r'] + color['g'] * 256.0 + color['b'] * 256.0 * 256.0;\n",
    "\n",
    "def unpack_color(f):\n",
    "    b = math.floor(f / 256.0 / 256.0)\n",
    "    g = math.floor((f - b * 256.0 * 256.0) / 256.0)\n",
    "    r = math.floor(f - b * 256.0 * 256.0 - g * 256.0)\n",
    "    return {'r':r,'g':g,'b':b}\n",
    "\n",
    "se01_color = {'r':25, 'g':75, 'b':255}\n",
    "se02_color = {'r':20, 'g':138, 'b':9}\n",
    "se03_color = {'r':227, 'g':30, 'b':30}\n",
    "ANSI_CODES = [\n",
    "    ('01', 'al'), ('02', 'ak'), ('04', 'az'), ('05', 'ar'), ('06', 'ca'),\n",
    "    ('08', 'co'), ('09', 'ct'), ('10', 'de'), ('11', 'dc'), ('12', 'fl'),\n",
    "    ('13', 'ga'), ('15', 'hi'), ('16', 'id'), ('17', 'il'), ('18', 'in'),\n",
    "    ('19', 'ia'), ('20', 'ks'), ('21', 'ky'), ('22', 'la'), ('23', 'me'),\n",
    "    ('24', 'md'), ('25', 'ma'), ('26', 'mi'), ('27', 'mn'), ('28', 'ms'),\n",
    "    ('29', 'mo'), ('30', 'mt'), ('31', 'ne'), ('32', 'nv'), ('33', 'nh'),\n",
    "    ('34', 'nj'), ('35', 'nm'), ('36', 'ny'), ('37', 'nc'), ('38', 'nd'),\n",
    "    ('39', 'oh'), ('40', 'ok'), ('41', 'or'), ('42', 'pa'), ('44', 'ri'),\n",
    "    ('45', 'sc'), ('46', 'sd'), ('47', 'tn'), ('48', 'tx'), ('49', 'ut'),\n",
    "    ('50', 'vt'), ('51', 'va'), ('53', 'wa'), ('54', 'wi'), ('55', 'wy'),\n",
    "    ('56', 'wv')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init_capture(\"capture/tabblock_2010\")\n",
    "capture_dir = \"capture/tabblock_2010/\"\n",
    "pa_id = 42\n",
    "init_capture(capture_dir)\n",
    "pa_url = format_tabblock_url(pa_id)\n",
    "pa_filename = capture_dir + os.path.basename(pa_url)\n",
    "if not os.path.isdir('./' + capture_dir):\n",
    "    download_file(pa_url, pa_filename)\n",
    "    unzip_tabblock(pa_filename, pa_filename.split('.')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command = \"createdb tl_2010_tabblock\"\n",
    "!$command\n",
    "command = \"psql -d tl_2010_tabblock -c 'CREATE EXTENSION postgis;'\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command = \"shp2pgsql -s 4269:4326 capture/tabblock_2010/tl_2010_%s_tabblock10/tl_2010_%s_tabblock10.shp tl_2010_tabblock10 | psql -q -d tl_2010_tabblock\" % (pa_id,pa_id)\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command = \"psql -d tl_2010_tabblock -c 'CREATE INDEX ON tl_2010_tabblock10 (geoid10);'\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command = \"psql -d tl_2010_tabblock -c 'CREATE INDEX ON tl_2010_tabblock10 USING GIST (geom);'\"\n",
    "!$command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "capture_dir = \"capture/lodes7/pa/\"\n",
    "init_capture(capture_dir)\n",
    "pa_url = format_lodes7_od_url('pa', 'main', 'JT00', '2011')\n",
    "pa_filename = capture_dir + os.path.basename(pa_url)\n",
    "if not os.path.isdir('./' + capture_dir):\n",
    "    download_file(pa_url, pa_filename) \n",
    "    gunzip_lodes(pa_filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open(\"pa-csv-to-psql.sql\", \"w\")\n",
    "f.write(create_od_table('pa'))\n",
    "f.write(copy_cvs_to_psql('pa', os.path.abspath(os.path.splitext(pa_filename)[0])))\n",
    "f.close()\n",
    "command = \"psql -d tl_2010_tabblock -f pa-csv-to-psql.sql\"\n",
    "!$command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "command = \"psql -d tl_2010_tabblock -c 'CREATE INDEX ON pa_od_jt00_2011 (gid);'\"\n",
    "!$command\n",
    "\n",
    "command = \"psql -d tl_2010_tabblock -c 'CREATE INDEX ON pa_od_jt00_2011 (w_geocode);'\"\n",
    "!$command\n",
    "\n",
    "command = \"psql -d tl_2010_tabblock -c 'CREATE INDEX ON pa_od_jt00_2011 (h_geocode);'\"\n",
    "!$command\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# faster\n",
    "# runs multiple queries to build rows\n",
    "# then runs multiple processes to process rows\n",
    "\n",
    "state = 'pa'\n",
    "dest = '%s-od-jt00-2011.bin' % state\n",
    "STEP = 100000 # run SQL query 100000 rows at a time\n",
    "    \n",
    "packed_se01_color = pack_color(se01_color)\n",
    "packed_se02_color = pack_color(se02_color)\n",
    "packed_se03_color = pack_color(se03_color)\n",
    "\n",
    "# find how many rows total:\n",
    "conn = psycopg2.connect(dbname=\"tl_2010_tabblock\", host=\"/var/run/postgresql\")\n",
    "rows = get_count(conn, '%s_od_jt00_2011' % state)\n",
    "TOTAL = rows[0][0]\n",
    "print 'Total Rows: %s' % TOTAL\n",
    "conn.close()\n",
    "\n",
    "def get_rows(index):\n",
    "    offset = index * STEP    \n",
    "    conn = psycopg2.connect(dbname=\"tl_2010_tabblock\", host=\"/var/run/postgresql\")\n",
    "    print \"Batch start: %s. Batch limit: %s\" % (offset, STEP)\n",
    "    query = (\n",
    "            \"select w.geom, h.geom, od.se01, od.se02, od.se03 \"\n",
    "            \"from %s_od_jt00_2011 od  \"\n",
    "            \"left join tl_2010_tabblock10 w on od.w_geocode = w.geoid10 \"\n",
    "            \"left join tl_2010_tabblock10 h on od.h_geocode = h.geoid10 \"\n",
    "            \"order by od.gid \"\n",
    "            \"limit %s \"\n",
    "            \"offset %s \"\n",
    "            ) % (state, STEP, offset)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(query)\n",
    "    rows = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return rows\n",
    "\n",
    "def process_row(row):\n",
    "    data = []\n",
    "    workGeom = row[0]\n",
    "    homeGeom = row[1]\n",
    "    se01 = row[2]\n",
    "    se02 = row[3]\n",
    "    se03 = row[4]\n",
    "    for i in range(se01):\n",
    "        wpoint = randomPoint(workGeom)\n",
    "        hpoint = randomPoint(homeGeom)\n",
    "        data += LonLatToPixelXY(wpoint)\n",
    "        data += LonLatToPixelXY(hpoint)\n",
    "        data.append(packed_se01_color)\n",
    "    for i in range(se02):\n",
    "        wpoint = randomPoint(workGeom)\n",
    "        hpoint = randomPoint(homeGeom)\n",
    "        data += LonLatToPixelXY(wpoint)\n",
    "        data += LonLatToPixelXY(hpoint)\n",
    "        data.append(packed_se02_color)\n",
    "    for i in range(se03):\n",
    "        wpoint = randomPoint(workGeom)\n",
    "        hpoint = randomPoint(homeGeom)\n",
    "        data += LonLatToPixelXY(wpoint)\n",
    "        data += LonLatToPixelXY(hpoint)\n",
    "        data.append(packed_se03_color)\n",
    "        \n",
    "    #print \"Randomizing points...\"\n",
    "    split = split_list(data,len(data)/3)\n",
    "    random.shuffle(split)        \n",
    "    data = []\n",
    "    for x in split:\n",
    "        for y in x:\n",
    "            data += [y]\n",
    "    return data\n",
    "\n",
    "        \n",
    "print \"Querying rows...\"\n",
    "index = range(0, TOTAL / STEP)\n",
    "pool = Pool(23)\n",
    "all_rows = pool.map(get_rows, index)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "rows = [row for rows in all_rows for row in rows] # flatten results\n",
    "print 'Resulting rows: %s ' % len(rows)\n",
    "\n",
    "print \"Processing rows...\"\n",
    "pool = Pool(23) # use 24 of available 32 cores. Let's not be greedy...\n",
    "results = pool.map(process_row, rows)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "print \"Appending results to %s\" % dest\n",
    "# at this point we have an array of arrays (e.g. [[73.1, 96.8, 73.2, 96.7, 625172], [73.2, 96.7, 73.1, 96.8, 622372], ...])\n",
    "results = [item for sublist in results for item in sublist] # flatten results\n",
    "array.array('f', results).tofile(open(dest, 'aw'))\n",
    "\n",
    "\n",
    "print \"Process finished.\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
